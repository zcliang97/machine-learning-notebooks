{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "\u001b[K    100% |████████████████████████████████| 317kB 4.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting keras-applications>=1.0.6 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl (51kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 15.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/site-packages (from keras) (1.15.4)\n",
      "Collecting pyyaml (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/2c/9417b5c774792634834e730932745bc09a7d36754ca00acf1ccd1ac2594d/PyYAML-5.1.tar.gz (274kB)\n",
      "\u001b[K    100% |████████████████████████████████| 276kB 3.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 14.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting h5py (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/c5/eec74d7324628f1b640c6e706981c4ed51afcaa1656ece26cb08d862598e/h5py-2.9.0-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (6.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 6.2MB 3.4MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting scipy>=0.14 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/6c/ccf7403d14f0ab0f20ce611696921f204f4ffce99a4fd383c892a6a7e9eb/scipy-1.2.1-cp37-cp37m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (27.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 27.3MB 1.7MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/site-packages (from keras) (1.12.0)\n",
      "Building wheels for collected packages: pyyaml\n",
      "  Building wheel for pyyaml (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/fliang/Library/Caches/pip/wheels/ad/56/bc/1522f864feb2a358ea6f1a92b4798d69ac783a28e80567a18b\n",
      "Successfully built pyyaml\n",
      "Installing collected packages: h5py, keras-applications, pyyaml, keras-preprocessing, scipy, keras\n",
      "Successfully installed h5py-2.9.0 keras-2.2.4 keras-applications-1.0.7 keras-preprocessing-1.0.9 pyyaml-5.1 scipy-1.2.1\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting torch\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/e2/40f7f017437139e5dc076ea5ad4207da61250cc078bceef7d6f333c1d05c/torch-1.1.0-cp37-none-macosx_10_7_x86_64.whl (88.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 88.9MB 657kB/s ta 0:00:011    28% |█████████▏                      | 25.5MB 3.6MB/s eta 0:00:18    42% |█████████████▊                  | 38.1MB 9.3MB/s eta 0:00:06    45% |██████████████▊                 | 40.8MB 4.7MB/s eta 0:00:11    64% |████████████████████▋           | 57.3MB 6.1MB/s eta 0:00:06    64% |████████████████████▊           | 57.5MB 5.3MB/s eta 0:00:06    67% |█████████████████████▌          | 59.7MB 4.7MB/s eta 0:00:07\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from torch) (1.15.4)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.1.0\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/1c/3ac472009a5c54ae7ec5a3294520ca36d1908cd1e5cf3e3fd923f9b7b31f/tensorflow-1.13.1-cp37-cp37m-macosx_10_11_x86_64.whl (73.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 73.6MB 815kB/s ta 0:00:011 0% |▏                               | 327kB 8.1MB/s eta 0:00:10    6% |██                              | 4.5MB 10.3MB/s eta 0:00:07    7% |██▌                             | 5.6MB 10.3MB/s eta 0:00:07    96% |██████████████████████████████▊ | 70.7MB 6.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.15.4)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.32.2)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.0.7)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.0.9)\n",
      "Collecting absl-py>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/3f/9b0355080b81b15ba6a9ffcf1f5ea39e307a2778b2f2dc8694724e8abd5b/absl-py-0.7.1.tar.gz (99kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 5.3MB/s a 0:00:011\n",
      "\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
      "\u001b[K    100% |████████████████████████████████| 368kB 2.7MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/site-packages (from tensorflow) (3.7.1)\n",
      "Collecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/82/60d5ec84dd2ed474aced1a1fd3cff932306c359ce97b2bb3ff5bc750d0d9/grpcio-1.20.1-cp37-cp37m-macosx_10_9_x86_64.whl (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 4.0MB/s ta 0:00:011    39% |████████████▌                   | 768kB 5.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.2MB 7.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow) (2.9.0)\n",
      "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/42/b4/f9afb3de9bd92d165e94a81f4048b373825009be9234f588a69afc64e7a1/mock-3.0.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow) (40.8.0)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<1.14.0,>=1.13.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/e4/d8c18f2555add57ff21bf25af36d827145896a07607486cc79a2aea641af/Markdown-3.1-py2.py3-none-any.whl (87kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 10.6MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.14.1)\n",
      "Building wheels for collected packages: absl-py, termcolor, gast\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/fliang/Library/Caches/pip/wheels/ee/98/38/46cbcc5a93cfea5492d19c38562691ddb23b940176c14f7b48\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/fliang/Library/Caches/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/fliang/Library/Caches/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "Successfully built absl-py termcolor gast\n",
      "Installing collected packages: absl-py, mock, tensorflow-estimator, grpcio, markdown, tensorboard, termcolor, gast, astor, tensorflow\n",
      "Successfully installed absl-py-0.7.1 astor-0.7.1 gast-0.2.2 grpcio-1.20.1 markdown-3.1 mock-3.0.4 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# download all python packages\n",
    "import sys\n",
    "!{sys.executable} -m pip install keras\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics\n",
    "A Neural Network is a collection of software \"neurons\" arranged in layers, connected together in a way that allows communication. By changing the values of the Weight (W) and the Bias (b), we can try to minimize the cost function of the NN.\n",
    "\n",
    "#### Single Neuron\n",
    "Each neuron receives a set of x-values (numbered from 1 to n) as an input and computes the predicted y-hat value. Vector **x** actually contains the values of the features in one of _m_ examples from the training set. Each unit has its own set of parameters, usually referred to as **w** (column vector of weights) and b (bias) which changes during the learning process. **In each iteration, the neuron calculates a weighted average of the values of the vector x**, based on the current weight vector **w** and adds bias. Finally, the result of this calculation is passed through a non-linear activation function _g_. \n",
    "\n",
    "<img src=\"images/single_neuron.png\" width=\"50%\">\n",
    "\n",
    "#### Single Layer\n",
    "Using the knowledge of what is happening inside a single unit and vectorize across full layer to combine those calculations into matrix equations. To unify the notation, the equations will be written for the selected layer _l_.\n",
    "\n",
    "#### Neural Network Workflow\n",
    "<img src=\"images/nn_flow.png\" width=\"50%\">\n",
    "\n",
    "##### Forward Propagation\n",
    "In the forward propagation phase, the activation function is applied to each node to predict the y_hat values from the given x_values and continues through the layers. Each layer can be seen as a vector which allows for progressing one layer at a time using linear algebra.\n",
    "\n",
    "##### Loss Function\n",
    "The loss function identifies how well the current predictions are doing. The loss function calculates how far we are from the ideal solution and we try to minize the difference. This is done through the **cost** and **accuracy** functions. One example of a of loss function is binary crossentropy.\n",
    "\n",
    "##### Backward Propagation\n",
    "Backward propagation serves to calculate the gradient effectively and gradient descent is using the calculated gradient to optimize. In NN, we calculate the gradient of the cost function in respect to its parameters but backpropagation is used to calculate the derivation of any function. The essence of this algorithm is to recursively apply chain rule by calculating a derivative of functions by assembling other functions whose derivatives are already known.\n",
    "<img src=\"images/nn_prop.png\" width=\"50%\">\n",
    "\n",
    "#### Updating Parameter Values\n",
    "Main purpose of this workflow process is to update the parameter values using gradient optimization. In this way, we can try to bring our target function closer to a minimum. We do this by using two variables `params_values` which stores current parameter values and `grad_values` which stores the cost derivatives with respect to those parameter values. Now by applying the following equations to each layer, we can optimize the parameters of the gradient. There are more complex optimizers later on.\n",
    "> $W^{[l]}$ = $W^{[l]}$ - $\\alpha$ $dW^{[l]}$\n",
    "\n",
    "> $b^{[l]}$ = $b^{[l]}$ - $\\alpha$ $db^{[l]}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "In neural networks, the activation function of a node defines the output of that node (or neuron) given an input or a set of inputs. The output is then used as input for the next node and so on until a desired solution to the original problem is found.\n",
    "\n",
    "#### ReLU\n",
    "ReLU is a rectified linear unit and is a type of activation function. It is mathematically _y=max(0, x)_. Visually it looks like the following:\n",
    "\n",
    "<img src=\"images/reLU.png\" width=\"50%\">\n",
    "\n",
    "ReLU is the most common activation function to use in neural networks (especialy for CNN).\n",
    "> If unsure about what activation function to use in a network, use ReLU.\n",
    "\n",
    "##### Functionality\n",
    "ReLU is linear for all **positive values** and zero for all **negative values**.\n",
    "\n",
    "This means that:\n",
    "* cheap to compute as there is no complicated math; model takes less time to run\n",
    "* converges faster, linearity means that the slope doesn't plateau or \"saturate\" when x gets large (like in sigmoid or tanh)\n",
    "* sparsely activated; since ReLU is zero for all negative inputs, its likely for any given unit to not activate at all (often desirable)\n",
    "\n",
    "#### Sigmoid\n",
    "Sigmoid has a characteristic \"S\" shape with equation _y = 1/(1+e^-x)_. Visually it looks like the following:\n",
    "\n",
    "<img src=\"images/sigmoid.png\" width=\"50%\">\n",
    "\n",
    "##### Functionality\n",
    "A sigmoid function is a bounded, differentiable, real function that is defined for all real input values and has a non-negative derivative at each point.\n",
    "\n",
    "In general, a sigmoid function is monotonic (only increases or only decreases) and has a first derivative with is bell shaped. A sigmoid function is constrained by a pair of horizontal asymptotes as x -> +/-inf.\n",
    "\n",
    "The sigmoid function is convex for values less than 0, and it is concave for values more than 0. Because of this, the sigmoid function and its similar compositions can possess multiple optima (optimal points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODING NEURAL NETWORK POINTS\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "# this creates a CNN\n",
    "con_layer = tf.layers.conv2d(\n",
    "    inputs = input_layer,\n",
    "    filters = 32,\n",
    "    kernel_size = [5, 5],\n",
    "    padding='same',\n",
    "    activation=tf.nn.relu\n",
    ")\n",
    "\n",
    "# keras\n",
    "from keras.layers import Actvation, Dense\n",
    "\n",
    "# this adds a ReLU layer to the current model\n",
    "model.add(Dense(64, actvation='relu'))\n",
    "\n",
    "# pytorch\n",
    "from torch.nn import RNN\n",
    "\n",
    "# this will add 2 CNN layers with ReLU\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 20, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(20, 64, 5),\n",
    "    nn.ReLU()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "To make the following neural network using KERAS.\n",
    "<img src=\"images/neural_network_architecture.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=2, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# X_train and y_train are data sets\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of Neural Networks\n",
    "#### Convolutional Neural Networks (CNN)\n",
    "#### Baysian Neural Networks (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
